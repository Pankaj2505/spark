{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec364ad8",
   "metadata": {},
   "source": [
    "History of Big-Data\n",
    "\n",
    "> as data volumn incresed , the power of storage and processing also increased.\n",
    "- Task associated with data\n",
    "    - Data caputure and ingestion\n",
    "    - Data Storage and Management\n",
    "    - Data Processing and Transformation\n",
    "    - Data Access and retrival\n",
    "\n",
    "\n",
    "\n",
    "- Data caputure and ingestion\n",
    "    - __data collection is gonna increase every day__ \n",
    "    - google search engine was reading each webpage, and capturing some data from it,\n",
    "    - caputuring how many users ad how often they are visiting.\n",
    "    - there is 5 property of data\n",
    "        - volumn,\n",
    "            - reading thousand of petabyte\n",
    "        - variety,\n",
    "            - what type of data we are reading (text, audio, vedio, binary, numerical)\n",
    "        - velocity,\n",
    "            - how often we are reading the data\n",
    "        - verasity,\n",
    "            - how much noise is in data\n",
    "        - value\n",
    "            - how much valuable your data is.\n",
    "    - IOT devices (device with sensor) they create peta bytes of data every year.\n",
    "- Data Storage and Management\n",
    "    - we uses various data base to store and manage data\n",
    "        - Boyes and cott, they came with an idea of relational database (store data in table)\n",
    "            - orcle,\n",
    "            - sql server\n",
    "            - postgres\n",
    "            - My SQL\n",
    "    - but as data volumn increased relation database started failing , as they are not desinged for petabytes level of data\n",
    "        - Google (larry page,Jeff Dean) came with an idea of distributed system\n",
    "            - Hadoop\n",
    "            - Map Reduce\n",
    "            - Spark\n",
    "            - Mongo DB\n",
    "        > __Every Tool has its own objective__\n",
    "- Data Processing and Transformation\n",
    "    - compute heavy task\n",
    "        - super computer system\n",
    "        - weather forcasting need to compute on many algortihm, here we do lot of optmization computing\n",
    "        - Deep learning(lots of computation is needed even for small dataset)\n",
    "        - Super computer are desinged for parallel processing . for example 4 core, can do 4 task parallely ,so supercomputer has 100 cores or more.\n",
    "        - two framework are popular for parallel processing\n",
    "            - MPI(1970)\n",
    "            - PVM(1980-1990)\n",
    "    - data heavy task\n",
    "        - Big data system\n",
    "        - (joining, grouping, count) these are data heavy task\n",
    "        - Traditional relation database sytem(before 2000)\n",
    "            - core idea: hardisk and ram is not cheap \n",
    "                - that's why we uses normalization to minimize the amount of data storage\n",
    "                - wait time is ok for query execution\n",
    "                - Database is hosted in single server, which may have many core for computation, but still there used to be a wait time invlolve in query execution.\n",
    "        -  Distributed storage system(Map Reduce)(2000)\n",
    "            - Core idea: Hard disk is cheap,RAM is expensive,  computation and low latency application is important\n",
    "                - Hadoop has designed HDFS(hadoop distributed file system) is the implemantation of map reduce\n",
    "                - hive is facebook implemantation of map reduce,this is a engine which convert sql query to map reduce queries\n",
    "                - pig desgined by yahoo, this is a engine which convert sql query to map reduce queries\n",
    "            - they have used a rack made by 10+ motherbored, each mother has its own harddisk, ram, cooling fan, processor(cpu)\n",
    "            - all these motherbord is connected using lan\n",
    "            - now we are storing the data across multiple harddisk( distributing the storage accross multiple harddisk)\n",
    "            - Scalable (as we can add more motherbord)\n",
    "            - Map Reduce, is a framework which helps to process through distributed storage.\n",
    "                - File system \n",
    "                    - its a orchastration software which, given a large data, distribute it data accross multiple storage.\n",
    "                - compute cordination system\n",
    "                    - given a task,  orchastration software, which used to pull data from various HDD, and do the task.\n",
    "              \n",
    "            - Hadoop used to stores intermediatory data to disk, as ram is expensive. so computation is very expensive.\n",
    "            \n",
    "            \n",
    "        - SPARK(2012)\n",
    "            - core idea : RAM is cheaper, harddisk is super cheap , low latency application is must\n",
    "            - now all the intermediatory data is stored in RAM.\n",
    "            - Spark is superset of Map- Reduce, intermediatory data is sotred in RAM, if its too much , then in harddisk\n",
    "            - pyspark is the language to work with spark\n",
    "                \n",
    "        \n",
    "        - GPU(2017)\n",
    "            - Graphics processing unit\n",
    "            - it sits beside CPU, and process all the graphics (game graphichs, video processing)\n",
    "            - deep learning on large dataset is both copute heavy and data heavy task\n",
    "     \n",
    "        - CLOUD computing\n",
    "    \n",
    "- Data Access and retrival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9c9206",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
